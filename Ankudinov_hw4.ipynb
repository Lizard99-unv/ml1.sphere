{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №4 - Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 10 мая 2021, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 10 мая, -4 балла после 08:30 17 мая, -6 баллов после 08:30 24 мая, -8 баллов после 08:30 31 мая.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0221, Задание 4] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Считаем производные для функций потерь (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
    "\n",
    "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
    "\n",
    "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
    "\n",
    "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваше решение тут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $a(x_i) = F(x_i) = f_0(x) + c_1f_1(x) + ... + c_nf_n(x)$\n",
    "\n",
    "Тогда таргетом будет: $-\\frac{dL}{dF}(x_i,F_{k-1}(x_i))$\n",
    "\n",
    "Вычислим производную для каждого лосса:\n",
    "\n",
    "1) $\\frac{dL}{dF} = 2(F(x_i) - y_i)$\n",
    "\n",
    "2) $\\frac{dL}{dF} = exp( -F(x_i) y_i) * (-y_i)$\n",
    "\n",
    "3) $\\frac{dL}{dF} = \\frac{exp( -F(x_i) y_i) * (-y_i)}{1 + exp( -F(x_i) y_i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем градиентный бустинг (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детали реализации:\n",
    "\n",
    "-- должно поддерживаться 3 функции потерь\n",
    "\n",
    "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
    "\n",
    "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
    "\n",
    "-- шаг в бустинге можно не подбирать, можно брать константный\n",
    "\n",
    "-- можно брать разные модели в качестве инициализации бустинга\n",
    "\n",
    "-- должны поддерживаться следующие параметры:\n",
    "\n",
    "а) число итераций\n",
    "б) размер шага\n",
    "в) процент случайных фичей при построении одного дерева\n",
    "д) процент случайных объектов при построении одного дерева\n",
    "е) параметры базового алгоритма (передавайте через **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradientBoostingClassifier:\n",
    "\n",
    "    def __init__(self, loss = \"mse\", learning_rate = 0.1, n_estimators = 100,\n",
    "                 colsample = 1.0, subsample = 1.0, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        loss -- один из 3 лоссов:\n",
    "        learning_rate -- шаг бустинга\n",
    "        n_estimators -- число итераций\n",
    "        colsample -- процент рандомных признаков при обучении одного алгоритма\n",
    "        subsample -- процент рандомных объектов при обучении одного алгоритма\n",
    "        args, kwargs -- параметры  базовых моделей\n",
    "        \"\"\"\n",
    "        self.loss = loss\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.colsample = colsample\n",
    "        self.subsample = subsample\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self.models = []\n",
    "        \n",
    "    def fit(self, X, y, base_model = DecisionTreeRegressor, init_model=None):\n",
    "        \"\"\"\n",
    "        X -- объекты для обучения:\n",
    "        y -- таргеты для обучения\n",
    "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
    "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
    "        \"\"\"\n",
    "        self.y = y\n",
    "        F = np.mean(y) * np.ones([y.shape[0]])\n",
    "        target = y\n",
    "        if init_model is None:\n",
    "            self.first = False\n",
    "            model = base_model(*self.args, **self.kwargs)\n",
    "        else:\n",
    "            self.first = True\n",
    "            model = init_model()\n",
    "        model.fit(X, target)\n",
    "        self.models.append(model)\n",
    "        F += self.learning_rate * model.predict(X).reshape([X.shape[0]])\n",
    "        for i in range(1, self.n_estimators):               \n",
    "            if self.loss == 'mse':\n",
    "                target = 2 * (y - F)\n",
    "            if self.loss == 'exp':\n",
    "                target = (np.exp(-F * y)) * y\n",
    "            if self.loss == 'log':\n",
    "                target = ((np.exp(-F * y)) * y) / (1 + np.exp(-F * y))\n",
    "            model = base_model(*self.args, **self.kwargs)\n",
    "            model.fit(X, target)\n",
    "            self.models.append(model)\n",
    "            F += self.learning_rate * model.predict(X).reshape([X.shape[0]])\n",
    "\n",
    "                   \n",
    "                   \n",
    "    def predict(self, X):\n",
    "        if self.first:\n",
    "            pred = self.learning_rate * self.models[0].predict(X).reshape([X.shape[0]])\n",
    "        else:\n",
    "            pred = np.ones([X.shape[0]]) * np.mean(self.y)\n",
    "        for i in range(1, self.n_estimators):\n",
    "            pred += self.learning_rate * self.models[i].predict(X).reshape([X.shape[0]])\n",
    "        return np.around(pred).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyGradientBoostingClassifier()\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбираем параметры (2 балла)\n",
    "\n",
    "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании нужно\n",
    "\n",
    "1) Построить график точности в зависимости от числа итераций на валидации.\n",
    "\n",
    "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "# Превращаем регрессию в классификацию\n",
    "y = (y > 2.0).astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kf = KFold(n_splits=5, shuffle =True)\n",
    "mod_scores = []\n",
    "for iters in range(1, 200, 10):\n",
    "    clf = MyGradientBoostingClassifier(n_estimators = iters)\n",
    "    indices = kf.split(X)\n",
    "    scores = []\n",
    "    for train_ind, test_ind in indices:\n",
    "        clf.fit(X[train_ind], y[train_ind])\n",
    "        scores.append(accuracy_score(y_true=y[test_ind], y_pred=clf.predict(X[test_ind])))\n",
    "    mod_scores.append(np.mean(np.array(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe2708e2a30>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(range(1,200, 10)),mod_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9637112403100776\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "best_res = 0\n",
    "for loss in ['mse', 'exp', 'log']:\n",
    "    clf = MyGradientBoostingClassifier(loss = loss)\n",
    "    indices = kf.split(X)\n",
    "    scores = []\n",
    "    for train_ind, test_ind in indices:\n",
    "        clf.fit(X[train_ind], y[train_ind])\n",
    "        scores.append(accuracy_score(y_true=y[test_ind], y_pred=clf.predict(X[test_ind])))\n",
    "    mean = np.mean(scores)\n",
    "    if mean > best_res:\n",
    "        print(mean)\n",
    "        best_res = mean\n",
    "        best_loss = loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mse'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9629360465116278\n",
      "0.9647771317829458\n",
      "0.9653100775193799\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "best_res = 0\n",
    "for rate in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    clf = MyGradientBoostingClassifier(learning_rate = rate)\n",
    "    indices = kf.split(X)\n",
    "    scores = []\n",
    "    for train_ind, test_ind in indices:\n",
    "        clf.fit(X[train_ind], y[train_ind])\n",
    "        scores.append(accuracy_score(y_true=y[test_ind], y_pred=clf.predict(X[test_ind])))\n",
    "    mean = np.mean(scores)\n",
    "    if mean > best_res:\n",
    "        print(mean)\n",
    "        best_res = mean\n",
    "        best_rate = rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BooBag BagBoo (1 балл)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем объединить бустинг и бэгинг. Давайте\n",
    "\n",
    "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
    "\n",
    "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-cdb585cab006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m my_clf = MyGradientBoostingClassifier(loss=best_loss, n_estimators_=120,\n\u001b[1;32m      3\u001b[0m                                      learning_rate=best_rate)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmy_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-f1ac1c7be5f5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, base_model, init_model)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mF\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mF\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mF\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                                         indices=indices)\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "my_clf = MyGradientBoostingClassifier(loss=best_loss, n_estimators_=120,\n",
    "                                     learning_rate=best_rate)\n",
    "my_clf.fit(X_train, y_train, base_model=RandomForestRegressor)\n",
    "accuracy_score(y_test, my_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4239bfb410144309a7bc8e71b00dbf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8575581395348837\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.dummy import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "def process_random_boost(i):\n",
    "    model = MyGradientBoostingClassifier()\n",
    "    samples_inds = np.random.randint(0, X_train.shape[0], size=int(X_train.shape[0] / N))\n",
    "    X_boost = X_train[samples_inds, :]\n",
    "    y_boost = y_train[samples_inds]\n",
    "    model.fit(X_boost, y_boost)\n",
    "    preds = model.predict(X_test)\n",
    "    with lock:\n",
    "        boots_res.append(preds)\n",
    "        pbar.update(1)\n",
    "N = 70\n",
    "with Pool(10) as pool, tqdm(N) as pbar:\n",
    "    boots_res = []\n",
    "    lock = pbar.get_lock()\n",
    "    pool.map(process_random_boost, range(N))\n",
    "pool.join()\n",
    "print(accuracy_score(y_test, np.sum(boots_res, axis=0) / N > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Умная инициализация (1 балл)\n",
    "\n",
    "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
    "\n",
    "Получилось ли улучшить качество? Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "my_clf = MyGradientBoostingClassifier()\n",
    "my_clf.fit(X=X_train, y=y_train, init_model=LinearRegression)\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier()\n",
    "my_clf.fit(X=X_train, y=y_train, init_model=RandomForestRegressor)\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier()\n",
    "my_clf.fit(X=X_train, y=y_train, init_model=SVR)\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видимо в алгоритме ошибка, но уже не успеваю её исправить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
